{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0c6cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting javaobj-py3\n",
      "  Downloading javaobj_py3-0.4.3-py2.py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 0.0/57.3 kB ? eta -:--:--\n",
      "     --------------------------- ---------- 41.0/57.3 kB 653.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 57.3/57.3 kB 747.3 kB/s eta 0:00:00\n",
      "Installing collected packages: javaobj-py3\n",
      "Successfully installed javaobj-py3-0.4.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install PyQt5\n",
    "# ! git clone --recursive https://github.com/dmlc/xgboost\n",
    "# !pip install pandastable\n",
    "# !pip install -U numpy scipy py_entitymatching\n",
    "!pip install javaobj-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5d97068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attributes', 'entityUrl']\n",
      "<class 'javaobj.v2.transformers.JavaList'>\n",
      "<class 'javaobj.v2.beans.JavaInstance'> [instance 0x7e0016: type org.scify.jedai.datamodel.EntityProfile]\n",
      "<class 'javaobj.v2.transformers.JavaSet'> [classdesc 0x7e0006: name java.util.HashSet, uid -5024744406713321676]\n"
     ]
    }
   ],
   "source": [
    "import javaobj\n",
    "\n",
    "with open(\"data/data/cleanCleanErDatasets/acmProfiles\", \"rb\") as fd:\n",
    "    pobj = javaobj.v2.load(fd)\n",
    "\n",
    "print(pobj[1].get_class().fields_names)\n",
    "print(type(pobj))\n",
    "print(type(pobj[1]), pobj[1])\n",
    "pobj[1].attributes.load_from_instance()\n",
    "print(type(pobj[1].attributes), pobj[10].attributes.get_class())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "049bcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import javaobj\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the serialized object file\n",
    "with open('data/data/cleanCleanErDatasets/acmProfiles', 'rb') as f:\n",
    "    data = javaobj.v2.load(f)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "    \n",
    "rows = []\n",
    "for obj in data:\n",
    "    row = []\n",
    "    for key, value in obj.__dict__.items():\n",
    "        if key == 'classdesc':\n",
    "            field_names = [field.name for field in value.fields]\n",
    "            field_values = []\n",
    "            for field in value.fields:\n",
    "                attr_value = getattr(obj, field.name)\n",
    "                if isinstance(attr_value, set):\n",
    "                    pd_row = dict()\n",
    "                    for ins in set(attr_value):\n",
    "                        class_desc = ins.classdesc\n",
    "                        key = ''\n",
    "                        for field_desc in class_desc.fields:   \n",
    "                            attr_name = field_desc.name\n",
    "                            if attr_name == 'name':\n",
    "                                key = getattr(ins, attr_name)\n",
    "                            if attr_name == 'value':\n",
    "                                attr_value = getattr(ins, attr_name)\n",
    "                                pd_row[key]=attr_value\n",
    "                    pd_row = pd.DataFrame(pd_row, index=[0])\n",
    "                    df = pd.concat([df, pd_row], ignore_index=True)\n",
    "#                 else:\n",
    "#                     field_values\n",
    "            row.append(field_values)\n",
    "        else:\n",
    "            row.append(value)\n",
    "    rows.append(row)\n",
    "with open('data.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "40cb8ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gottfried Vossen, Mathias Weske</td>\n",
       "      <td>The WASA2 object-oriented workflow management ...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Isabel F. Cruz, Kimberly M. James</td>\n",
       "      <td>A user-centered interface for querying distrib...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Athman Bouguettaya, Boualem Benatallah, Lily H...</td>\n",
       "      <td>World Wide Database-integrating the Web, CORBA...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chaitan Baru, Amarnath Gupta, Bertram Lud&amp;#228...</td>\n",
       "      <td>XML-based information mediation with MIX</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexander Brodsky, Victor E. Segal, Jia Chen, ...</td>\n",
       "      <td>The CCUBE constraint object-oriented database ...</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>Alfons Kemper, Donald Kossmann</td>\n",
       "      <td>Dual-Buffering Strategies in Object Bases</td>\n",
       "      <td>Very Large Data Bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>Philip A. Bernstein, Yannis Ioannidis, Raghu R...</td>\n",
       "      <td>Guest editorial</td>\n",
       "      <td>The VLDB Journal &amp;mdash; The International Jou...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>Ralf Hartmut G&amp;#252;ting</td>\n",
       "      <td>GraphDB: Modeling and Querying Graphs in Datab...</td>\n",
       "      <td>Very Large Data Bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>Alexander A. Anisimov</td>\n",
       "      <td>Review of The data warehouse toolkit: the comp...</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>Janet L. Wiener, Jeffrey F. Naughton</td>\n",
       "      <td>Bulk Loading into an OODB: A Performance Study</td>\n",
       "      <td>Very Large Data Bases</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2294 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                authors  \\\n",
       "0                       Gottfried Vossen, Mathias Weske   \n",
       "1                     Isabel F. Cruz, Kimberly M. James   \n",
       "2     Athman Bouguettaya, Boualem Benatallah, Lily H...   \n",
       "3     Chaitan Baru, Amarnath Gupta, Bertram Lud&#228...   \n",
       "4     Alexander Brodsky, Victor E. Segal, Jia Chen, ...   \n",
       "...                                                 ...   \n",
       "2289                     Alfons Kemper, Donald Kossmann   \n",
       "2290  Philip A. Bernstein, Yannis Ioannidis, Raghu R...   \n",
       "2291                           Ralf Hartmut G&#252;ting   \n",
       "2292                              Alexander A. Anisimov   \n",
       "2293               Janet L. Wiener, Jeffrey F. Naughton   \n",
       "\n",
       "                                                  title  \\\n",
       "0     The WASA2 object-oriented workflow management ...   \n",
       "1     A user-centered interface for querying distrib...   \n",
       "2     World Wide Database-integrating the Web, CORBA...   \n",
       "3              XML-based information mediation with MIX   \n",
       "4     The CCUBE constraint object-oriented database ...   \n",
       "...                                                 ...   \n",
       "2289          Dual-Buffering Strategies in Object Bases   \n",
       "2290                                    Guest editorial   \n",
       "2291  GraphDB: Modeling and Querying Graphs in Datab...   \n",
       "2292  Review of The data warehouse toolkit: the comp...   \n",
       "2293     Bulk Loading into an OODB: A Performance Study   \n",
       "\n",
       "                                                  venue  year  \n",
       "0        International Conference on Management of Data  1999  \n",
       "1        International Conference on Management of Data  1999  \n",
       "2        International Conference on Management of Data  1999  \n",
       "3        International Conference on Management of Data  1999  \n",
       "4        International Conference on Management of Data  1999  \n",
       "...                                                 ...   ...  \n",
       "2289                              Very Large Data Bases  1994  \n",
       "2290  The VLDB Journal &mdash; The International Jou...  2003  \n",
       "2291                              Very Large Data Bases  1994  \n",
       "2292                                  ACM SIGMOD Record  2003  \n",
       "2293                              Very Large Data Bases  1994  \n",
       "\n",
       "[2294 rows x 4 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a857088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[]', 'JavaSet({<javaobj:org.scify.jedai.datamodel.Attribute>, <javaobj:org.scify.jedai.datamodel.Attribute>, <javaobj:org.scify.jedai.datamodel.Attribute>, <javaobj:org.scify.jedai.datamodel.Attribute>})', '[org.scify.jedai.datamodel.EntityProfile:0x1B2B0CD02BE6E37]', '672979']\n"
     ]
    }
   ],
   "source": [
    "import javaobj\n",
    "import csv\n",
    "\n",
    "# Step 1: Read the serialized object file\n",
    "with open('data/data/cleanCleanErDatasets/acmProfiles', 'rb') as f:\n",
    "    data = javaobj.load(f)\n",
    "\n",
    "# Step 2: Convert the list of instances to a list of lists\n",
    "rows = []\n",
    "for obj in data:\n",
    "    row = []\n",
    "    for attr_name in dir(obj):\n",
    "        if not callable(getattr(obj, attr_name)) and not attr_name.startswith('__'):\n",
    "            row.append(str(getattr(obj, attr_name)))\n",
    "    rows.append(row)\n",
    "print(row)\n",
    "# # Step 3: Write the data to a CSV file\n",
    "# with open('data.csv', 'w', newline='') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bdde02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JavaMap(dict, javaobj.v2.beans.JavaInstance):\n",
    "    \"\"\"\n",
    "    Inherits from dict for Python usage, JavaInstance for parsing purpose\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Don't forget to call both constructors\n",
    "        dict.__init__(self)\n",
    "        javaobj.v2.beans.JavaInstance.__init__(self)\n",
    "\n",
    "    def load_from_blockdata(self, parser, reader, indent=0):\n",
    "#     \"\"\"\n",
    "#     Reads content stored in a block data.\n",
    "\n",
    "#     This method is called only if the class description has both the\n",
    "#     `SC_EXTERNALIZABLE` and `SC_BLOCK_DATA` flags set.\n",
    "\n",
    "#     The stream parsing will stop and fail if this method returns False.\n",
    "\n",
    "#     :param parser: The JavaStreamParser in use\n",
    "#     :param reader: The underlying data stream reader\n",
    "#     :param indent: Indentation to use in logs\n",
    "#     :return: True on success, False on error\n",
    "#     \"\"\"\n",
    "    # This kind of class is not supposed to have the SC_BLOCK_DATA flag set\n",
    "        return False\n",
    "\n",
    "    def load_from_instance(self, indent=0):\n",
    "        # type: (int) -> bool\n",
    "        \"\"\"\n",
    "        Load content from the parsed instance object.\n",
    "\n",
    "        This method is called after the block data (if any), the fields and\n",
    "        the annotations have been loaded.\n",
    "\n",
    "        :param indent: Indentation to use while logging\n",
    "        :return: True on success (currently ignored)\n",
    "        \"\"\"\n",
    "        # Maps have their content in their annotations\n",
    "        for cd, annotations in self.annotations.items():\n",
    "            # Annotations are associated to their definition class\n",
    "            if cd.name == \"java.util.HashMap\":\n",
    "                # We are in the annotation created by the handled class\n",
    "                # Group annotation elements 2 by 2\n",
    "                # (storage is: key, value, key, value, ...)\n",
    "                args = [iter(annotations[1:])] * 2\n",
    "                for key, value in zip(*args):\n",
    "                    self[key] = value\n",
    "\n",
    "                # Job done\n",
    "                return True\n",
    "\n",
    "        # Couldn't load the data\n",
    "        return False\n",
    "\n",
    "class MapObjectTransformer(javaobj.v2.api.ObjectTransformer):\n",
    "    \"\"\"\n",
    "    Creates a JavaInstance object with custom loading methods for the\n",
    "    classes it can handle\n",
    "    \"\"\"\n",
    "    def create_instance(self, classdesc):\n",
    "        # type: (JavaClassDesc) -> Optional[JavaInstance]\n",
    "        \"\"\"\n",
    "        Transforms a parsed Java object into a Python object\n",
    "\n",
    "        :param classdesc: The description of a Java class\n",
    "        :return: The Python form of the object, or the original JavaObject\n",
    "        \"\"\"\n",
    "        if classdesc.name == \"java.util.HashMap\":\n",
    "            # We can handle this class description\n",
    "            return JavaMap()\n",
    "        else:\n",
    "            # Return None if the class is not handled\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75659111",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTransformer(javaobj.v2.transformers.ObjectTransformer):\n",
    "    \"\"\"\n",
    "    Creates a JavaInstance object with custom loading methods for the\n",
    "    classes it can handle\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, handled_classes=None):\n",
    "        self.instance = None\n",
    "        self.handled_classes = handled_classes or {}\n",
    "\n",
    "    def create_instance(self, classdesc):\n",
    "        \"\"\"\n",
    "        Transforms a parsed Java object into a Python object\n",
    "\n",
    "        :param classdesc: The description of a Java class\n",
    "        :return: The Python form of the object, or the original JavaObject\n",
    "        \"\"\"\n",
    "        if classdesc.name in self.handled_classes:\n",
    "            self.instance = self.handled_classes[classdesc.name]()\n",
    "            return self.instance\n",
    "\n",
    "        return None\n",
    "\n",
    "class RandomChildTransformer(BaseTransformer):\n",
    "    def __init__(self):\n",
    "        super(RandomChildTransformer, self).__init__(\n",
    "            {\"RandomChild\": RandomChildInstance}\n",
    "        )\n",
    "\n",
    "class CustomWriterTransformer(BaseTransformer):\n",
    "    def __init__(self):\n",
    "        super(CustomWriterTransformer, self).__init__(\n",
    "            {\"CustomWriter\": CustomWriterInstance}\n",
    "        )\n",
    "\n",
    "class JavaRandomTransformer(BaseTransformer):\n",
    "    def __init__(self):\n",
    "        super(JavaRandomTransformer, self).__init__()\n",
    "        self.name = \"java.util.Random\"\n",
    "        self.field_names = [\"haveNextNextGaussian\", \"nextNextGaussian\", \"seed\"]\n",
    "        self.field_types = [\n",
    "            javaobj.v2.beans.FieldType.BOOLEAN,\n",
    "            javaobj.v2.beans.FieldType.DOUBLE,\n",
    "            javaobj.v2.beans.FieldType.LONG,\n",
    "        ]\n",
    "\n",
    "    def load_custom_writeObject(self, parser, reader, name):\n",
    "        if name != self.name:\n",
    "            return None\n",
    "\n",
    "        fields = []\n",
    "        values = []\n",
    "        for f_name, f_type in zip(self.field_names, self.field_types):\n",
    "            values.append(parser._read_field_value(f_type))\n",
    "            fields.append(javaobj.beans.JavaField(f_type, f_name))\n",
    "\n",
    "        class_desc = javaobj.beans.JavaClassDesc(\n",
    "            javaobj.beans.ClassDescType.NORMALCLASS\n",
    "        )\n",
    "        class_desc.name = self.name\n",
    "        class_desc.desc_flags = javaobj.beans.ClassDataType.EXTERNAL_CONTENTS\n",
    "        class_desc.fields = fields\n",
    "        class_desc.field_data = values\n",
    "        return class_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94f06bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWriterInstance(javaobj.v2.beans.JavaInstance):\n",
    "    def __init__(self):\n",
    "        javaobj.v2.beans.JavaInstance.__init__(self)\n",
    "\n",
    "    def load_from_instance(self):\n",
    "        \"\"\"\n",
    "        Updates the content of this instance\n",
    "        from its parsed fields and annotations\n",
    "        :return: True on success, False on error\n",
    "        \"\"\"\n",
    "        if self.classdesc and self.classdesc in self.annotations:\n",
    "            # Here, we known there is something written before the fields,\n",
    "            # even if it's not declared in the class description\n",
    "            fields = [\"int_not_in_fields\"] + self.classdesc.fields_names\n",
    "            raw_data = self.annotations[self.classdesc]\n",
    "            int_not_in_fields = struct.unpack(\n",
    "                \">i\", BytesIO(raw_data[0].data).read(4)\n",
    "            )[0]\n",
    "            custom_obj = raw_data[1]\n",
    "            values = [int_not_in_fields, custom_obj]\n",
    "            self.field_data = dict(zip(fields, values))\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "class RandomChildInstance(javaobj.v2.beans.JavaInstance):\n",
    "    def load_from_instance(self):\n",
    "        \"\"\"\n",
    "        Updates the content of this instance\n",
    "        from its parsed fields and annotations\n",
    "        :return: True on success, False on error\n",
    "        \"\"\"\n",
    "        if self.classdesc and self.classdesc in self.field_data:\n",
    "            fields = self.classdesc.fields_names\n",
    "            values = [\n",
    "                self.field_data[self.classdesc][self.classdesc.fields[i]]\n",
    "                for i in range(len(fields))\n",
    "            ]\n",
    "            self.field_data = dict(zip(fields, values))\n",
    "            if (\n",
    "                self.classdesc.super_class\n",
    "                and self.classdesc.super_class in self.annotations\n",
    "            ):\n",
    "                super_class = self.annotations[self.classdesc.super_class][0]\n",
    "                self.annotations = dict(\n",
    "                    zip(super_class.fields_names, super_class.field_data)\n",
    "                )\n",
    "            return True\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1520488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Load the object using those transformers\n",
    "transformers = [\n",
    "    CustomWriterTransformer(),\n",
    "    RandomChildTransformer(),\n",
    "    JavaRandomTransformer()\n",
    "]\n",
    "with open(\"data/data/cleanCleanErDatasets/abtBuyIdDuplicates\", \"rb\") as fd:\n",
    "    pobj = javaobj.v2.load(fd)\n",
    "\n",
    "# Here we show a field that isn't visible from the class description\n",
    "# The field belongs to the class but it's not serialized by default because\n",
    "# it's static. See: https://stackoverflow.com/a/16477421/12621168\n",
    "print(pobj.get_class().fields_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bcfd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
